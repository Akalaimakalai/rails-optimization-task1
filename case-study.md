# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики

Была сформулирована в задаче:
Добиться того, чтобы программа корректно обработала файл data_large.txt за 30 секунд

Метрика: Время обработки файла data_large.txt

Бюджет: 30 секунд

## Данные по асимптотике

1000: 0.072944 x0
2000: 0.222400 x3
4000: 0.764133 x3,5
8000: 2.832144 x4
16000: 16.096870 x5,7

попробуем взять файл в 16000 записей и заставить его работать за 1 секунду.
